{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "5006941e-44ff-4e27-f53e-31bf87221334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.228 üöÄ Python-3.10.13 torch-2.1.0 CUDA:0 (NVIDIA A10, 24043MiB)\n",
            "Setup complete ‚úÖ (12 CPUs, 31.1 GB RAM, 395.6/913.8 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Dec 21 15:26:20 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A10                     Off | 00000000:01:00.0 Off |                  Off |\n",
            "|  0%   49C    P0              61W / 150W |   6560MiB / 24564MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Predict\n",
        "\n",
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/config/) in the YOLOv8 [Docs](https://docs.ultralytics.com).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n"
          ]
        }
      ],
      "source": [
        "# –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –Ω–∞—à –Ω–æ—É—Ç–±—É–∫ –∑–∞–ø—É—â–µ–Ω –≤ –∫–∞—Ç–∞–ª–æ–≥–µ '/'\n",
        "import os\n",
        "\n",
        "print(os.getcwd()) # –≤—ã–≤–µ–¥–µ—Ç '/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "# –∏–∑–º–µ–Ω–∏–º –Ω–∞ –Ω—É–∂–Ω—ã–π –Ω–∞–º\n",
        "os.chdir('/workspace')\n",
        "print(os.getcwd()) # –≤—ã–≤–µ–¥–µ—Ç /workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8l-seg.pt')  # load an official model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /workspace/humans.jpg: 448x640 24 persons, 1 car, 2 traffic lights, 2 umbrellas, 2 handbags, 78.5ms\n",
            "Speed: 2.1ms preprocess, 78.5ms inference, 218.0ms postprocess per image at shape (1, 3, 448, 640)\n"
          ]
        }
      ],
      "source": [
        "test_image_path = \"humans.jpg\"\n",
        "result = model.predict(test_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ‚ö†Ô∏è TensorRT requires GPU export, automatically assigning device=0\n",
            "Ultralytics YOLOv8.0.228 üöÄ Python-3.10.13 torch-2.1.0 CUDA:0 (NVIDIA A10, 24043MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8l-seg.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (88.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 2.8s, saved as 'yolov8l-seg.onnx' (175.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.4.3.1...\n",
            "[12/21/2023-15:26:25] [TRT] [I] [MemUsageChange] Init CUDA: CPU +564, GPU +0, now: CPU 1609, GPU 7844 (MiB)\n",
            "[12/21/2023-15:26:25] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +433, GPU +104, now: CPU 2061, GPU 7948 (MiB)\n",
            "[12/21/2023-15:26:25] [TRT] [I] ----------------------------------------------------------------\n",
            "[12/21/2023-15:26:25] [TRT] [I] Input filename:   yolov8l-seg.onnx\n",
            "[12/21/2023-15:26:25] [TRT] [I] ONNX IR version:  0.0.8\n",
            "[12/21/2023-15:26:25] [TRT] [I] Opset version:    17\n",
            "[12/21/2023-15:26:25] [TRT] [I] Producer name:    pytorch\n",
            "[12/21/2023-15:26:25] [TRT] [I] Producer version: 2.1.0\n",
            "[12/21/2023-15:26:25] [TRT] [I] Domain:           \n",
            "[12/21/2023-15:26:25] [TRT] [I] Model version:    0\n",
            "[12/21/2023-15:26:25] [TRT] [I] Doc string:       \n",
            "[12/21/2023-15:26:25] [TRT] [I] ----------------------------------------------------------------\n",
            "[12/21/2023-15:26:25] [TRT] [W] onnx2trt_utils.cpp:369: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 116, 8400) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(1, 32, 160, 160) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as yolov8l-seg.engine\n",
            "[12/21/2023-15:26:31] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1293, GPU +360, now: CPU 3552, GPU 8016 (MiB)\n",
            "[12/21/2023-15:26:31] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +34, now: CPU 3553, GPU 8050 (MiB)\n",
            "[12/21/2023-15:26:31] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[12/21/2023-15:26:53] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.\n",
            "[12/21/2023-15:27:52] [TRT] [I] Detected 1 inputs and 5 output network tensors.\n",
            "[12/21/2023-15:27:52] [TRT] [I] Total Host Persistent Memory: 209680\n",
            "[12/21/2023-15:27:52] [TRT] [I] Total Device Persistent Memory: 106496\n",
            "[12/21/2023-15:27:52] [TRT] [I] Total Scratch Memory: 134217728\n",
            "[12/21/2023-15:27:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 0 MiB\n",
            "[12/21/2023-15:27:52] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 109.068ms to assign 15 blocks to 329 nodes requiring 206307344 bytes.\n",
            "[12/21/2023-15:27:52] [TRT] [I] Total Activation Memory: 206307344\n",
            "[12/21/2023-15:27:52] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +34, now: CPU 3779, GPU 8266 (MiB)\n",
            "[12/21/2023-15:27:52] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
            "[12/21/2023-15:27:52] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
            "[12/21/2023-15:27:52] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ‚úÖ 91.2s, saved as 'yolov8l-seg.engine' (177.9 MB)\n",
            "\n",
            "Export complete (91.2s)\n",
            "Results saved to \u001b[1m/workspace\u001b[0m\n",
            "Predict:         yolo predict task=segment model=yolov8l-seg.engine imgsz=640  \n",
            "Validate:        yolo val task=segment model=yolov8l-seg.engine imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'yolov8l-seg.engine'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.export(format=\"engine\", simplify=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a model\n",
        "model = YOLO(\"yolov8l-seg.engine\")  # load an official model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading yolov8l-seg.engine for TensorRT inference...\n",
            "[12/21/2023-15:29:09] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
            "\n",
            "[12/21/2023-15:29:09] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 3560, GPU 7992 (MiB)\n",
            "[12/21/2023-15:29:09] [TRT] [I] Loaded engine size: 177 MiB\n",
            "[12/21/2023-15:29:09] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 3759, GPU 8202 (MiB)\n",
            "[12/21/2023-15:29:09] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
            "[12/21/2023-15:29:09] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 3581, GPU 8202 (MiB)\n",
            "[12/21/2023-15:29:09] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
            "\n",
            "image 1/1 /workspace/humans.jpg: 640x640 23 persons, 1 car, 2 traffic lights, 2 umbrellas, 2 handbags, 9.8ms\n",
            "Speed: 1.2ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "result = model.predict(test_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-pose.pt to 'yolov8l-pose.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85.3M/85.3M [00:34<00:00, 2.57MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load a model\n",
        "model = YOLO('yolov8l-pose.pt')  # load an official model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /workspace/humans.jpg: 448x640 16 persons, 11.8ms\n",
            "Speed: 1.2ms preprocess, 11.8ms inference, 6.1ms postprocess per image at shape (1, 3, 448, 640)\n"
          ]
        }
      ],
      "source": [
        "result = model.predict(test_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ‚ö†Ô∏è TensorRT requires GPU export, automatically assigning device=0\n",
            "Ultralytics YOLOv8.0.228 üöÄ Python-3.10.13 torch-2.1.0 CUDA:0 (NVIDIA A10, 24043MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8l-pose.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 56, 8400) (85.3 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 2.9s, saved as 'yolov8l-pose.onnx' (169.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.4.3.1...\n",
            "[12/21/2023-15:34:13] [TRT] [I] The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
            "\n",
            "[12/21/2023-15:34:13] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 3768, GPU 8922 (MiB)\n",
            "[12/21/2023-15:34:13] [TRT] [I] ----------------------------------------------------------------\n",
            "[12/21/2023-15:34:13] [TRT] [I] Input filename:   yolov8l-pose.onnx\n",
            "[12/21/2023-15:34:13] [TRT] [I] ONNX IR version:  0.0.8\n",
            "[12/21/2023-15:34:13] [TRT] [I] Opset version:    17\n",
            "[12/21/2023-15:34:13] [TRT] [I] Producer name:    pytorch\n",
            "[12/21/2023-15:34:13] [TRT] [I] Producer version: 2.1.0\n",
            "[12/21/2023-15:34:13] [TRT] [I] Domain:           \n",
            "[12/21/2023-15:34:13] [TRT] [I] Model version:    0\n",
            "[12/21/2023-15:34:13] [TRT] [I] Doc string:       \n",
            "[12/21/2023-15:34:13] [TRT] [I] ----------------------------------------------------------------\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 56, 8400) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as yolov8l-pose.engine\n",
            "[12/21/2023-15:34:19] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +32, now: CPU 3957, GPU 8822 (MiB)\n",
            "[12/21/2023-15:34:19] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 3957, GPU 8854 (MiB)\n",
            "[12/21/2023-15:34:19] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[12/21/2023-15:34:33] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.\n",
            "[12/21/2023-15:35:11] [TRT] [I] Detected 1 inputs and 4 output network tensors.\n",
            "[12/21/2023-15:35:12] [TRT] [I] Total Host Persistent Memory: 196944\n",
            "[12/21/2023-15:35:12] [TRT] [I] Total Device Persistent Memory: 0\n",
            "[12/21/2023-15:35:12] [TRT] [I] Total Scratch Memory: 134217728\n",
            "[12/21/2023-15:35:12] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 0 MiB\n",
            "[12/21/2023-15:35:12] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 105.647ms to assign 11 blocks to 319 nodes requiring 203030528 bytes.\n",
            "[12/21/2023-15:35:12] [TRT] [I] Total Activation Memory: 203030528\n",
            "[12/21/2023-15:35:12] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +36, now: CPU 3981, GPU 9064 (MiB)\n",
            "[12/21/2023-15:35:12] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
            "[12/21/2023-15:35:12] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
            "[12/21/2023-15:35:12] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ‚úÖ 61.8s, saved as 'yolov8l-pose.engine' (172.3 MB)\n",
            "\n",
            "Export complete (61.9s)\n",
            "Results saved to \u001b[1m/workspace\u001b[0m\n",
            "Predict:         yolo predict task=pose model=yolov8l-pose.engine imgsz=640  \n",
            "Validate:        yolo val task=pose model=yolov8l-pose.engine imgsz=640 data=/usr/src/app/ultralytics/datasets/coco-pose.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'yolov8l-pose.engine'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.export(format=\"engine\", simplify=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a model\n",
        "model = YOLO(\"yolov8l-pose.engine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading yolov8l-pose.engine for TensorRT inference...\n",
            "[12/21/2023-15:35:12] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
            "\n",
            "[12/21/2023-15:35:12] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 3771, GPU 8794 (MiB)\n",
            "[12/21/2023-15:35:12] [TRT] [I] Loaded engine size: 172 MiB\n",
            "[12/21/2023-15:35:12] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +32, now: CPU 3964, GPU 9000 (MiB)\n",
            "[12/21/2023-15:35:12] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
            "[12/21/2023-15:35:12] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +32, now: CPU 3792, GPU 9000 (MiB)\n",
            "[12/21/2023-15:35:12] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
            "\n",
            "image 1/1 /workspace/humans.jpg: 640x640 16 persons, 8.7ms\n",
            "Speed: 1.3ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "result = model.predict(test_image_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv8 Tutorial",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ultra_yolov8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c43743495b2c62d3a4e2c702fe9226f33958afa220c4e4f392be647b90a51546"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
